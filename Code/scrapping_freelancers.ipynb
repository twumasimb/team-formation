{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pickle\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating user template\n",
    "class UserProfile():\n",
    "    def __init__(self) -> None:\n",
    "        self.id = None\n",
    "        self.skills = []\n",
    "        self.location = None\n",
    "        self.reviews = None\n",
    "        self.progress = None\n",
    "\n",
    "    def user(self):\n",
    "        dictionary = {\n",
    "            'id': self.id,\n",
    "            'skills':self.skills,\n",
    "            'location': self.location,\n",
    "            'reviews':self.reviews,\n",
    "            'progress':self.progress\n",
    "        }\n",
    "        return dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Other important attributes\n",
    "id_no = 1\n",
    "\n",
    "profiles = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to retrieve the web page.\n",
      "Failed to retrieve the web page.\n",
      "Failed to retrieve the web page.\n",
      "Failed to retrieve the web page.\n",
      "Failed to retrieve the web page.\n",
      "Failed to retrieve the web page.\n",
      "Failed to retrieve the web page.\n",
      "Failed to retrieve the web page.\n",
      "Failed to retrieve the web page.\n",
      "Failed to retrieve the web page.\n",
      "Failed to retrieve the web page.\n",
      "Failed to retrieve the web page.\n",
      "Failed to retrieve the web page.\n",
      "Failed to retrieve the web page.\n"
     ]
    }
   ],
   "source": [
    "url_list = [f\"https://www.freelancer.com/freelancers/skills/website-design/{i}\" for i in range(1, 10000)]\n",
    "# url_list = [\"https://www.freelancer.com/freelancers/skills/website-design/1\", \"https://www.freelancer.com/freelancers/skills/website-design/2\"]\n",
    "\n",
    "for url in url_list:\n",
    "        # Send an HTTP GET request to the URL\n",
    "        response = requests.get(url)\n",
    "\n",
    "        # Check if the request was successful\n",
    "        if response.status_code == 200:\n",
    "            # Parse the HTML content of the page using BeautifulSoup\n",
    "            soup1 = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "            file_path = f\"new_webpages\\webpage_{url_list.index(url)}.html\"\n",
    "\n",
    "            # Save the HTML data to a file\n",
    "            with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "                file.write(soup1.prettify())\n",
    "        else:\n",
    "            print(\"Failed to retrieve the web page.\")\n",
    "\n",
    "        # Read the local webpage\n",
    "        try:\n",
    "            # Open the file for reading\n",
    "            with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "                # Read the content of the file\n",
    "                html_content = file.read()\n",
    "\n",
    "        except FileNotFoundError:\n",
    "            print(\"File not found:\", file_path)\n",
    "        except Exception as e:\n",
    "            print(\"An error occurred:\", str(e))\n",
    "\n",
    "        soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "        # Find all divs with class=\"freelancer-details\"\n",
    "        freelancer_details_divs = soup.find_all('div', class_='freelancer-details')\n",
    "\n",
    "        # Iterate over each freelancer-details div\n",
    "        for freelancer_details_div in freelancer_details_divs:\n",
    "\n",
    "            user = UserProfile()\n",
    "\n",
    "            # Get the User details\n",
    "            id = id_no\n",
    "            location = freelancer_details_div.find('div', class_='user-location').get_text().strip()\n",
    "            reviews = freelancer_details_div.find('a', class_='directory-freelancer-rating').get_text().strip()\n",
    "            progress = freelancer_details_div.find('span', class_='Earnings-label').get_text().strip()\n",
    "\n",
    "            #Assigning the data to the user profile\n",
    "            user.id = id\n",
    "            user.location = location\n",
    "            user.reviews = int(re.search(r'\\d+',reviews).group())\n",
    "            user.progress = float(progress)\n",
    "\n",
    "            # Find anchor tags inside the div with class=\"top skills\"\n",
    "            top_skills_div = freelancer_details_div.find('div', class_='top-skills')\n",
    "\n",
    "            # Extract and print the text enclosed by the anchor tags\n",
    "            anchor_tags = top_skills_div.find_all('a')\n",
    "            for anchor_tag in anchor_tags:\n",
    "                skill = anchor_tag.get_text().strip() # Get the text enclosed by the anchor tag\n",
    "                user.skills.append(skill)\n",
    "\n",
    "            profiles.append(user.user())\n",
    "            id_no += 1\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(profiles, open('usr_data/webdev.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2093"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(profiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pickle.load(open('usr_data/webdev.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2093\n"
     ]
    }
   ],
   "source": [
    "print(len(data))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
